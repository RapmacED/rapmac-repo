{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: beautifulsoup4 in /opt/homebrew/lib/python3.9/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.9/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: requests in /opt/homebrew/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from requests) (2.0.12)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /opt/homebrew/lib/python3.9/site-packages (0.25.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.9/site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /opt/homebrew/lib/python3.9/site-packages (from openai) (1.4.2)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /opt/homebrew/lib/python3.9/site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.9/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/lib/python3.9/site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /opt/homebrew/lib/python3.9/site-packages (from openai) (1.5.2.221213)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.9/site-packages (from openai) (1.22.4)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/lib/python3.9/site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas>=1.2.3->openai) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas-stubs>=1.1.0.11->openai) (2022.7.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: chronological in /opt/homebrew/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.9/site-packages (from chronological) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.9/site-packages (from chronological) (0.21.0)\n",
      "Requirement already satisfied: loguru in /opt/homebrew/lib/python3.9/site-packages (from chronological) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (4.4.0)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (1.5.2.221213)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (3.0.10)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (2.27.1)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (4.64.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.9/site-packages (from openai->chronological) (1.22.4)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/lib/python3.9/site-packages (from openpyxl>=3.0.7->openai->chronological) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas>=1.2.3->openai->chronological) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas>=1.2.3->openai->chronological) (2022.1)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas-stubs>=1.1.0.11->openai->chronological) (2022.7.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai->chronological) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai->chronological) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai->chronological) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.20->openai->chronological) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai->chronological) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.10/site-packages (4.25.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/raph/Library/Python/3.10/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/raph/Library/Python/3.10/lib/python/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install openai --upgrade\n",
    "!pip install chronological\n",
    "!pip3 install python-dotenv\n",
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.25.0\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /opt/homebrew/lib/python3.10/site-packages\n",
      "Requires: numpy, openpyxl, pandas, pandas-stubs, requests, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from bs4.element import Comment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from transformers import GPT2TokenizerFast\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two functions to keep only the visible elements on a webpage (possibly the article written in this page)\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def split_str_halves(string):\n",
    "  n = len(string)\n",
    "  print(n)\n",
    "  global part1\n",
    "  global part2\n",
    "  if n%2 == 0:\n",
    "    part1 = string[0:n//2]\n",
    "    part2 = string[n//2:]\n",
    "    return part1,part2\n",
    "  else:\n",
    "    part1 = string[0:(n//2+1)]\n",
    "    part2 = string[(n//2+1):]\n",
    "    return part1,part2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 1\n",
    "#Get the source code of a webpage using BeautifulSoup\n",
    "headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36\"}\n",
    "r1 = requests.get('https://www.saagie.com/fr/ingenieur-data-science/', headers=headers)\n",
    "#print(r1.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##STEP 2 \n",
    "#Keep only the visible elements of the webpage\n",
    "\n",
    "#print(text_from_html(r1.text))\n",
    "text_from_webpage = text_from_html(r1.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"part1\"\n",
    "myVars = vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3804 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'text_from' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m token_size \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:    \n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tokenizer(text_from_webpage)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m4097\u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m :\n\u001b[0;32m----> 8\u001b[0m         text_from\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_from' is not defined"
     ]
    }
   ],
   "source": [
    "##STEP 3\n",
    "#Split the webpage to stay under GPT3 limitation of 4097 (prompt + result)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "token_size = False\n",
    "parts = 0\n",
    "while token_size == False:    \n",
    "    if len(tokenizer(text_from_webpage)['input_ids']) > 4097//2 :\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Hello la mif\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Hello \n"
     ]
    }
   ],
   "source": [
    "split_str_halves('Hello la mif')\n",
    "print(part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5783 tokens (2783 in your prompt; 3000 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m##STEP 4\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#Give ChatGPT the webpage with only the visible elements and tell him to keep sentences with subject, verb and complement only\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      6\u001b[0m     \u001b[39m#prompt='Isole les phrases qui possèdent un sujet, un verbe et un complément dans ce texte' + text_from_webpage,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     prompt\u001b[39m=\u001b[39;49mtext_from_webpage,\n\u001b[1;32m      8\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[39m# Get the generated text from the response\u001b[39;00m\n\u001b[1;32m     14\u001b[0m text \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/openai/api_requestor.py:181\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    172\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    173\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/openai/api_requestor.py:396\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    390\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    393\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    397\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m         ),\n\u001b[1;32m    399\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/openai/api_requestor.py:429\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    427\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    430\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    431\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 5783 tokens (2783 in your prompt; 3000 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "##STEP 4\n",
    "#Give ChatGPT the webpage with only the visible elements and tell him to keep sentences with subject, verb and complement only\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    #prompt='Isole les phrases qui possèdent un sujet, un verbe et un complément dans ce texte' + text_from_webpage,\n",
    "    prompt=text_from_webpage,\n",
    "    model=\"text-davinci-003\",\n",
    "    max_tokens=3000,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Get the generated text from the response\n",
    "text = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ces dernières années, les entreprises ont compris l’importance d’analyser les données pour en tirer des bénéfices en matière de choix stratégiques, d’accompagnement client et de positionnement vis-à-vis de la concurrence. Pour cela, elles ont créé un pôle data qui regroupe notamment des ingénieurs data science, ou data scientists, pour travailler sur le sujet.\n",
      "\n",
      "1. Qui est l’ingénieur data science ?\n",
      "\n",
      "L’ingénieur data science, ou le métier de data scientist, est un nouveau profil apparu cette dernière décennie afin de faire face aux besoins des entreprises en matière de traitement des données.\n",
      "\n",
      "2. Le rôle de l’ingénieur data science dans votre entreprise\n",
      "\n",
      "L’ingénieur data science, ou data scientist, a pour but de collecter, de trier, d’organiser, d’analyser et d’exploiter des données afin de résoudre les problématiques l’entreprise comme l’amélioration de la qualité ou de la productivité. Il participe à un projet data avec ses collègues de l’équipe data.\n",
      "\n",
      "A. Le rôle de l’ingénieur data science\n",
      "\n",
      "L’ingénieur data science travaille au sein de l’équipe d’experts data de votre entreprise. Il peut exercer plusieurs métiers : data analyst, data scientist, data architect, data manager… La diversité des métiers possibles pour le poste de data scientist permet de nombreuses évolutions. Les missions du data scientist sont :\n",
      "\n",
      "- le choix des outils d’analyse,\n",
      "- la définition de solutions de stockage des données,\n",
      "- le recueil et l’analyse des données pertinentes pour l’entreprise,\n",
      "- la construction d’algorithmes complexes permettant d’améliorer les résultats de recherches et de ciblage,\n",
      "- l’élaboration de modèles de prédictions afin d’anticiper les comportements clients,\n",
      "- la création de rendus visuels afin de rendre les résultats lisibles et exploitables par tous les métiers,\n",
      "- la contribution à la prise de décision et à la formulation de recommandations,\n",
      "- la veille technologique.\n",
      "\n",
      "B. Les relations entre l’ingénieur data science et les collaborateurs de votre entreprise\n",
      "\n",
      "L’ingénieur data science doit également avoir un contact très proche avec le business pour bien le comprendre, répondre à son besoin et trouver des solutions. Pour cela, il est important qu’il soit en contact avec les différents départements de l’entreprise, en fonction du projet : le département informatique, communication, financier, marketing… Une bonne transversalité dans la communication et une méthodologie DataOps sont des moyens pour mener au succès des projets data. Pour l’intégration de l’ingénieur data dans l’entreprise, il est important de bien intégrer l’équipe data au sein de votre entreprise.\n",
      "\n",
      "C. Le marché de l’emploi pour l’ingénieur data science\n",
      "\n",
      "Les ingénieurs data science sont aujourd’hui très recherchés pour plusieurs raisons :\n",
      "\n",
      "- les métiers du Big Data et la révolution numérique des entreprises sont en plein développement ;\n",
      "- les formations de data scientist sont encore en nombre trop faible par rapport à la demande ;\n",
      "- il s’agit de nouveaux profils ;\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "#print(text_from_webpage)\n",
    "text = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"output_chat.txt\")\n",
    "file_obj = open(\"output_chat.txt\", \"w\")\n",
    "file_obj.write(text)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
